# streamlit_app.py
import streamlit as st
import pandas as pd
import numpy as np
import io, tempfile, os, time
from audio_recorder_streamlit import audio_recorder
import speech_recognition as sr
from gtts import gTTS
from googletrans import Translator

# --- Try to import transformers LLM; if not available, we'll fall back ---
USE_MODEL = False
model = None
tokenizer = None
try:
    from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
    st.info("Attempting to load small LLM (flan-t5-small). This may take a while on first run...")
    # lazy load with cache to avoid repeated downloads
    @st.cache_resource(show_spinner=False)
    def load_llm():
        tok = AutoTokenizer.from_pretrained("google/flan-t5-small")
        m = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-small")
        p = pipeline("text2text-generation", model=m, tokenizer=tok, max_length=256)
        return p
    try:
        model = load_llm()
        USE_MODEL = True
        st.success("LLM loaded: answers will be generated by a small LLM.")
    except Exception as e:
        st.warning("LLM load failed; falling back to local retrieval. " + str(e))
        USE_MODEL = False
except Exception:
    st.info("Transformers not available in runtime ‚Äî will use TF-IDF fallback.")

# ---------------------------
# Load KB and mandi data (sample)
# ---------------------------
@st.cache_data(show_spinner=False)
def load_data():
    kb = pd.read_csv("data/knowledge.csv")
    prices = pd.read_csv("data/mandi_prices.csv")
    return kb, prices

try:
    kb, prices = load_data()
except Exception:
    st.error("Missing data files. Ensure `data/knowledge.csv` and `data/mandi_prices.csv` exist in repo.")
    st.stop()

corpus = kb["content"].fillna("").tolist()
topics = kb["topic"].tolist()

# TF-IDF fallback
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
@st.cache_resource(show_spinner=False)
def build_vectorizer(c):
    vec = TfidfVectorizer(stop_words="english", ngram_range=(1,2), min_df=1)
    X = vec.fit_transform(c)
    return vec, X

vectorizer, kb_matrix = build_vectorizer(corpus)

translator = Translator()

st.set_page_config(page_title="AgroSaarthi (AI)", layout="wide")
st.title("üåæ AgroSaarthi ‚Äî AI Assistant for Farmers")
st.caption("Voice/text Q&A + sample mandi prices. LLM used when available; otherwise TF-IDF fallback (free).")

# Sidebar settings
with st.sidebar:
    st.header("Settings")
    mode = st.radio("Mode", ["Ask (AI)", "Mandi Prices"], index=0)
    voice_out = st.checkbox("Voice output (gTTS)", value=False)
    tts_lang = st.selectbox("TTS language", ["en", "hi", "kn", "ta", "te", "mr", "bn", "gu"], index=0)
    st.markdown("---")
    st.write("LLM status: " + ("Enabled" if USE_MODEL else "Disabled - TF-IDF fallback"))

# Utility functions
def retrieve_tfidf_answer(query, top_k=3):
    if not query.strip(): 
        return None, []
    q_vec = vectorizer.transform([query])
    sims = cosine_similarity(q_vec, kb_matrix).ravel()
    top_idx = np.argsort(sims)[::-1][:top_k]
    tops = [{"topic": topics[i], "content": corpus[i], "score": float(sims[i])} for i in top_idx]
    best = tops[0]["content"] if tops else ""
    return best, tops

def generate_with_llm(prompt):
    # prompt should be a question; we format lightly
    if model is None:
        return None
    try:
        out = model(prompt, max_length=256, do_sample=False)
        if isinstance(out, list):
            return out[0]["generated_text"]
        return str(out)
    except Exception as e:
        return None

def speak_text(text, lang_code="en"):
    try:
        tts = gTTS(text=text, lang=lang_code)
        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        tts.save(tmp.name)
        return tmp.name
    except Exception as e:
        st.warning("TTS error: " + str(e))
        return None

# Main UI
if mode == "Ask (AI)":
    st.subheader("Ask anything about crops, pests, irrigation, mandi prices or schemes")
    col1, col2 = st.columns([2,1])
    with col1:
        typed = st.text_input("Type your question (or record on right):", placeholder="e.g., How to treat tomato blight?")
        ask_btn = st.button("Ask")
    with col2:
        st.write("Or record voice:")
        audio_bytes = audio_recorder(pause_threshold=2.0, sample_rate=16000, recording_color="#e63946")
        recognized_text = ""
        if audio_bytes is not None and len(audio_bytes) > 0:
            try:
                recognizer = sr.Recognizer()
                with sr.AudioFile(io.BytesIO(audio_bytes)) as source:
                    audio = recognizer.record(source)
                recognized_text = recognizer.recognize_google(audio)
                st.info(f"Recognized: {recognized_text}")
            except sr.UnknownValueError:
                st.warning("Couldn't transcribe audio. Try typing.")
            except Exception as e:
                st.warning("Transcription error: " + str(e))

    final_q = (recognized_text.strip() if recognized_text else (typed or "").strip())

    if ask_btn or recognized_text:
        if not final_q:
            st.warning("Please type or record your question.")
        else:
            st.markdown("**Question:** " + final_q)
            answer_text = None
            # Prefer LLM (if loaded), else TF-IDF retrieval
            if USE_MODEL:
                prompt = f"Answer concisely and practically for a farmer. Q: {final_q}"
                answer_text = generate_with_llm(prompt)
                # if LLM fails, fallback
                if not answer_text:
                    st.warning("LLM failed ‚Äî using retrieval fallback.")
            if not answer_text:
                ans, refs = retrieve_tfidf_answer(final_q, top_k=3)
                if ans:
                    answer_text = ans
                else:
                    answer_text = "Sorry ‚Äî I don't have enough info. Try rephrasing or use mandi mode."

            st.success(answer_text)

            # Show references if retrieval used
            if not USE_MODEL:
                _, refs = retrieve_tfidf_answer(final_q, top_k=3)
                with st.expander("Source references"):
                    for i, r in enumerate(refs, start=1):
                        st.markdown(f"**{i}. {r['topic']}** (score: {r['score']:.3f}) ‚Äî {r['content'][:300]}{'...' if len(r['content'])>300 else ''}")

            # Translate and TTS
            if voice_out:
                try:
                    tts_text = answer_text
                    if tts_lang != "en":
                        trans = translator.translate(answer_text, dest=tts_lang)
                        tts_text = trans.text
                        st.write(f"üåê Translated ({tts_lang}): {tts_text}")
                    mp3 = speak_text(tts_text, lang_code=tts_lang)
                    if mp3:
                        st.audio(mp3, format="audio/mp3")
                except Exception as e:
                    st.warning("Voice output error: " + str(e))

else:
    st.subheader("Mandi Prices (sample dataset)")
    states = sorted(prices["state"].unique().tolist())
    state = st.selectbox("State", states, index=0)
    districts = sorted(prices[prices["state"]==state]["district"].unique().tolist())
    district = st.selectbox("District", districts, index=0)
    crops = sorted(prices[(prices["state"]==state) & (prices["district"]==district)]["crop"].unique().tolist())
    crop = st.selectbox("Crop", crops, index=0)
    subset = prices[(prices["state"]==state) & (prices["district"]==district) & (prices["crop"]==crop)]
    if not subset.empty:
        row = subset.iloc[0]
        st.success(f"**{crop}** in **{district}, {state}**: ‚Çπ{int(row['min_price'])}‚Äì‚Çπ{int(row['max_price'])} per {row['unit']}")
        st.dataframe(subset[["state","district","market","crop","min_price","max_price","unit"]], use_container_width=True)
    else:
        st.warning("No data for this selection.")

